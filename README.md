
# ğŸ–¼ï¸ Image Caption Generator using Python (CNN + LSTM)

This project uses deep learning techniques (Convolutional Neural Networks + LSTM) to automatically generate captions for images â€” just like a human!

---

## ğŸ“Œ Project Description

Humans can look at an image and instantly understand its context. Can a computer do the same? With recent advancements in deep learning, this is possible.

This project demonstrates how to train a model to generate meaningful captions for images using:
- **CNN (InceptionV3)**: For image feature extraction
- **LSTM (RNN)**: For sequence modeling to generate captions


## ğŸ“‚ Folder Structure

```

image_caption_generator
â”‚   .gitattributes
â”‚   app.py
â”‚
â”œâ”€â”€â”€dataset
â”‚   â”‚   caption_model.h5
â”‚   â”‚   caption_model.keras
â”‚   â”‚   cleaned_captions.txt
â”‚   â”‚   Flickr8k.token.txt
â”‚   â”‚   image_features.pkl
â”‚   â”‚   tokenizer.pkl
â”‚   â”‚
â”‚   â””â”€â”€â”€Flickr8k_text
â”‚       â”‚   CrowdFlowerAnnotations.txt
â”‚       â”‚   ExpertAnnotations.txt
â”‚       â”‚   Flickr8k.lemma.token.txt
â”‚       â”‚   Flickr8k.token.txt
â”‚       â”‚   Flickr_8k.devImages.txt
â”‚       â”‚   Flickr_8k.testImages.txt
â”‚       â”‚   Flickr_8k.trainImages.txt
â”‚       â”‚   
â”‚       â”‚
â”‚       â””â”€â”€â”€__MACOSX
â”‚               ._Flickr8k.lemma.token.txt
â”‚
â””â”€â”€â”€src
        caption_generator.py
        caption_preprocessing.py
        feature_extraction.py
        model_training.py

```

## ğŸ› ï¸ Installation

### âœ… Step 1: Clone the repo

```bash
git clone https://github.com/yourusername/image-caption-generator.git
cd image-caption-generator
````

### âœ… Step 2: Install dependencies

```bash
pip install tensorflow keras numpy pillow matplotlib tqdm pickle5
```

### âœ… Step 3: Download Dataset

* [Flickr8k Images](https://github.com/jbrownlee/Datasets/releases/download/Flickr8k/Flickr8k_Dataset.zip)
* [Flickr8k Captions](https://github.com/jbrownlee/Datasets/releases/download/Flickr8k/Flickr8k_text.zip)

Place them in the `dataset/` folder.

---

## ğŸš€ How to Run

### ğŸ”¹ Step 1: Extract features from images

```python
from utils.image_preprocessing import extract_features
features = extract_features("dataset/Flickr8k_Dataset")
# Save to disk using pickle
```

### ğŸ”¹ Step 2: Preprocess captions and fit tokenizer

```python
from utils.data_preprocessing import clean_caption
# Process captions, build tokenizer, and save it
```

### ğŸ”¹ Step 3: Train the model

```bash
python app.py
```

---

## ğŸ¤– How It Works

1. Extract features from images using InceptionV3.
2. Clean and process text captions.
3. Train a combined CNN + LSTM model on image-text pairs.
4. Generate captions for new images.

---

## ğŸ§ª Example Output

> ğŸ–¼ï¸ Input: A dog running in the park
> ğŸ“ Output: `"startseq a dog is running through the grass endseq"`

---

## ğŸ“¦ Requirements

* Python 3.7+
* TensorFlow 2.x
* NumPy, Pillow, Matplotlib, tqdm, nltk
* OpenCV (optional for UI)

---

## ğŸ“ˆ Future Improvements

* Beam Search for better caption generation
* Streamlit UI for image upload & display
* Support for larger datasets (e.g., MS-COCO)
